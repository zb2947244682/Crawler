# ğŸš€ çˆ¬è™«APIæœåŠ¡

åŸºäºNode.js + Playwrightçš„ç°ä»£åŒ–çˆ¬è™«APIæœåŠ¡ï¼Œæ”¯æŒæµè§ˆå™¨è‡ªåŠ¨åŒ–ã€é¡µé¢æ¸²æŸ“ã€æ•°æ®æŠ“å–ç­‰åŠŸèƒ½ã€‚

## âš¡ Windowså¿«é€Ÿå¼€å§‹

```batch
# 1. ç¡®ä¿å·²å®‰è£…Node.js (https://nodejs.org/)
# 2. åŒå‡» start.bat ä¸€é”®å¯åŠ¨æœåŠ¡
start.bat

# 3. åœ¨æµè§ˆå™¨è®¿é—®: http://localhost:3000
# 4. è¿è¡Œæµ‹è¯•: åŒå‡» test.bat
```

## âœ¨ ç‰¹æ€§

- ğŸ–¥ï¸ **æµè§ˆå™¨è‡ªåŠ¨åŒ–**: åŸºäºPlaywrightï¼Œæ”¯æŒChrome/Chromium
- ğŸ”„ **ä¼šè¯ç®¡ç†**: æ”¯æŒå¤šæµè§ˆå™¨ä¼šè¯å¹¶å‘å¤„ç†
- ğŸª **Cookieç®¡ç†**: å®Œæ•´çš„Cookieè®¾ç½®å’Œè·å–åŠŸèƒ½
- ğŸ“‹ **Headeræ§åˆ¶**: è‡ªå®šä¹‰HTTPè¯·æ±‚å¤´
- ğŸ“¸ **æˆªå›¾åŠŸèƒ½**: æ”¯æŒå…¨é¡µæˆ–å…ƒç´ æˆªå›¾
- ğŸ¯ **å…ƒç´ æ“ä½œ**: ç‚¹å‡»ã€ç­‰å¾…ã€æ»šåŠ¨ç­‰äº¤äº’
- ğŸ³ **Dockeréƒ¨ç½²**: å¼€ç®±å³ç”¨çš„å®¹å™¨åŒ–éƒ¨ç½²
- ğŸ”’ **åæ£€æµ‹**: é›†æˆstealthæ’ä»¶ï¼Œç»•è¿‡åŸºæœ¬åçˆ¬æ£€æµ‹

## ğŸ—ï¸ æ¶æ„

```
crawler-api/
â”œâ”€â”€ server.js          # ä¸»æœåŠ¡å…¥å£
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ crawler.js     # çˆ¬è™«APIè·¯ç”±
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ browser.js     # æµè§ˆå™¨æ± ç®¡ç†
â”œâ”€â”€ Dockerfile         # Dockeræ„å»ºé…ç½®
â”œâ”€â”€ docker-compose.yml # å®¹å™¨ç¼–æ’
â””â”€â”€ test.js           # APIæµ‹è¯•è„šæœ¬
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨Dockerï¼ˆæ¨èï¼‰

```bash
# 1. æ„å»ºé•œåƒ
docker build -t crawler-api .

# 2. è¿è¡Œå®¹å™¨
docker run -d -p 3000:3000 --name crawler-api crawler-api

# æˆ–ä½¿ç”¨docker-compose
docker-compose up -d
```

### æœ¬åœ°å¼€å‘ï¼ˆWindowsï¼‰

```batch
# 1. å®‰è£…ä¾èµ–
npm install

# 2. å¯åŠ¨æœåŠ¡
npm run dev

# 3. è¿è¡Œæµ‹è¯•
npm test
```

**å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼š**
```batch
# åŒå‡»è¿è¡Œ start.bat å³å¯ä¸€é”®å¯åŠ¨æœåŠ¡
start.bat

# æˆ–è¿è¡Œæµ‹è¯•
test.bat
```

## ğŸ“– APIæ–‡æ¡£

æœåŠ¡å¯åŠ¨åè®¿é—® `http://localhost:3000` æŸ¥çœ‹å®Œæ•´çš„APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹ã€‚

### æ ¸å¿ƒAPIæ¥å£

#### 1. åˆ›å»ºæµè§ˆå™¨ä¼šè¯
```http
POST /api/browser/create
```

**è¯·æ±‚ä½“:**
```json
{
  "userAgent": "è‡ªå®šä¹‰User-Agent",
  "viewport": {"width": 1920, "height": 1080},
  "headless": true,
  "proxy": {"server": "http://proxy:8080"},
  "extraHTTPHeaders": {"X-Custom": "value"}
}
```

**å“åº”:**
```json
{
  "success": true,
  "sessionId": "abc-123-def"
}
```

#### 2. å¯¼èˆªåˆ°é¡µé¢
```http
POST /api/browser/{sessionId}/navigate
```

**è¯·æ±‚ä½“:**
```json
{
  "url": "https://example.com",
  "waitUntil": "domcontentloaded",
  "timeout": 30000
}
```

#### 3. è·å–HTMLå†…å®¹
```http
GET /api/browser/{sessionId}/html
```

**å“åº”:**
```json
{
  "success": true,
  "html": "<html>...</html>",
  "url": "https://example.com"
}
```

#### 4. è®¾ç½®Cookies
```http
POST /api/browser/{sessionId}/cookies/set
```

**è¯·æ±‚ä½“:**
```json
{
  "cookies": [
    {
      "name": "token",
      "value": "abc123",
      "domain": "example.com",
      "path": "/",
      "expires": -1
    }
  ]
}
```

#### 5. é¡µé¢æ»šåŠ¨
```http
POST /api/browser/{sessionId}/scroll
```

**è¯·æ±‚ä½“:**
```json
{
  "scrollToBottom": true
}
// æˆ–
{
  "x": 0,
  "y": 1000,
  "behavior": "smooth"
}
// æˆ–æ»šåŠ¨åˆ°æŒ‡å®šå…ƒç´ 
{
  "selector": "#target-element"
}
```

#### 6. æˆªå–é¡µé¢æˆªå›¾
```http
POST /api/browser/{sessionId}/screenshot
```

**è¯·æ±‚ä½“:**
```json
{
  "fullPage": true,
  "type": "png",
  "quality": 80
}
```

**å“åº”:**
```json
{
  "success": true,
  "screenshot": "base64ç¼–ç çš„å›¾ç‰‡æ•°æ®",
  "size": 12345
}
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œå†…ç½®æµ‹è¯•è„šæœ¬ï¼š

```bash
npm test
```

æˆ–æ‰‹åŠ¨æµ‹è¯•ï¼š

```bash
# åˆ›å»ºä¼šè¯
curl -X POST http://localhost:3000/api/browser/create \
  -H "Content-Type: application/json" \
  -d '{}'

# å¯¼èˆªé¡µé¢
curl -X POST http://localhost:3000/api/browser/{sessionId}/navigate \
  -H "Content-Type: application/json" \
  -d '{"url": "https://httpbin.org/html"}'

# è·å–HTML
curl http://localhost:3000/api/browser/{sessionId}/html

# æˆªå–é¡µé¢æˆªå›¾
curl -X POST http://localhost:3000/api/browser/{sessionId}/screenshot \
  -H "Content-Type: application/json" \
  -d '{"fullPage": true, "type": "png"}'

# å…³é—­ä¼šè¯
curl -X POST http://localhost:3000/api/browser/{sessionId}/close
```

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡

- `PORT`: æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤3000ï¼‰
- `NODE_ENV`: è¿è¡Œç¯å¢ƒï¼ˆdevelopment/productionï¼‰
- `PLAYWRIGHT_CHROMIUM_EXECUTABLE_PATH`: Chromiumå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„

### æµè§ˆå™¨æ± é…ç½®

åœ¨ `utils/browser.js` ä¸­å¯ä»¥è°ƒæ•´ï¼š

- `MAX_BROWSERS`: æœ€å¤§æµè§ˆå™¨å®ä¾‹æ•°
- `BROWSER_TIMEOUT`: æµè§ˆå™¨å®ä¾‹è¶…æ—¶æ—¶é—´

## ğŸ”§ é«˜çº§ç”¨æ³•

### ä»£ç†è®¾ç½®

```json
{
  "proxy": {
    "server": "http://proxy.example.com:8080",
    "username": "user",
    "password": "pass"
  }
}
```

### è‡ªå®šä¹‰JavaScriptæ‰§è¡Œ

é€šè¿‡å¯¼èˆªæ¥å£çš„æ‰©å±•å‚æ•°å¯ä»¥æ‰§è¡Œè‡ªå®šä¹‰JSï¼š

```json
{
  "url": "https://example.com",
  "jsScript": "document.title = 'Modified Title';"
}
```

### ç­‰å¾…ç­–ç•¥

```json
{
  "waitUntil": "networkidle",  // ç½‘ç»œç©ºé—²
  "waitForSelector": "#content", // ç­‰å¾…å…ƒç´ 
  "timeout": 30000
}
```

## ğŸ³ Dockeréƒ¨ç½²

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# ä½¿ç”¨docker-composeéƒ¨ç½²
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f crawler-api

# æ‰©å®¹å®ä¾‹
docker-compose up -d --scale crawler-api=3
```

### èµ„æºé™åˆ¶

```yaml
services:
  crawler-api:
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
```

## ğŸ”’ å®‰å…¨æ³¨æ„äº‹é¡¹

1. **ä¼šè¯ç®¡ç†**: åŠæ—¶å…³é—­ä¸éœ€è¦çš„æµè§ˆå™¨ä¼šè¯
2. **èµ„æºé™åˆ¶**: è®¾ç½®åˆç†çš„å†…å­˜å’ŒCPUé™åˆ¶
3. **è®¿é—®æ§åˆ¶**: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ·»åŠ APIè®¤è¯
4. **æ—¥å¿—ç›‘æ§**: ç›‘æ§APIä½¿ç”¨æƒ…å†µå’Œé”™è¯¯æ—¥å¿—

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æœåŠ¡æ—¥å¿—ï¼š`docker-compose logs crawler-api`
2. æ£€æŸ¥å¥åº·çŠ¶æ€ï¼š`GET /health`
3. æŸ¥çœ‹æ´»è·ƒä¼šè¯ï¼š`GET /api/sessions`
